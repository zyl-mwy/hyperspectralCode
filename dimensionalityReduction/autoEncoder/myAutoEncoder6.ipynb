{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: QtAgg\n",
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\software\\anaconda_new\\envs\\hyperSpectralDataHandle\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:162: UserWarning: pylab import has clobbered these variables: ['step', 'spy']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Load Model complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Test]: 0it [00:00, ?it/s]e:\\software\\anaconda_new\\envs\\hyperSpectralDataHandle\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "[Test]: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mouse Functions:\n",
      "----------------\n",
      "left-click & drag        ->   Rotate cube\n",
      "CTRL+left-click & drag   ->   Zoom in/out\n",
      "SHIFT+left-click & drag  ->  Pan\n",
      "\n",
      "Keybinds:\n",
      "---------\n",
      "l       -> toggle light\n",
      "t/g     -> stretch/compress z-dimension\n",
      "h       -> print help message\n",
      "q       -> close window\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "%pylab\n",
    "import spectral as spy\n",
    "import scipy\n",
    "import os \n",
    "from spectral import view_cube\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from torchvision import transforms, utils\n",
    "import tqdm\n",
    "\n",
    "# from pylab import *\n",
    "spy.settings.WX_GL_DEPTH_SIZE = 16\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class CIFAR10_IMG(Dataset):\n",
    "\n",
    "    def __init__(self, root, train='Train', transform = None, target_transform=None):\n",
    "        super(CIFAR10_IMG, self).__init__()\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        if self.train=='Train':\n",
    "            file_annotation = root + '/FinalTrain.xlsx'\n",
    "            img_folder = root + r'/drawRigion\\runs\\labelme2coco\\hyperspectralDataSplit'\n",
    "        elif self.train=='Val':\n",
    "            file_annotation = root + '/FinalVal.xlsx'\n",
    "            img_folder = root + r'/drawRigion\\runs\\labelme2coco\\hyperspectralDataSplit'\n",
    "        elif self.train=='Test':\n",
    "            file_annotation = root + '/FinalTest.xlsx'\n",
    "            img_folder = root + r'/drawRigion\\runs\\labelme2coco\\hyperspectralDataSplit' # '/drawRigion/maskPicNormal'\n",
    "        myAnnotion = pd.read_excel(file_annotation).values\n",
    "        # assert len(data_dict['images'])==len(data_dict['categories'])\n",
    "        self.num_data = myAnnotion.shape[0]\n",
    "        self.filenames = []\n",
    "        self.labels1 = []\n",
    "        self.labels2 = []\n",
    "        self.img_folder = img_folder\n",
    "        # print('---', self.img_folder)\n",
    "        for i in range(self.num_data):\n",
    "            self.filenames.append(myAnnotion[i][2])\n",
    "            self.labels1.append(myAnnotion[i][8])\n",
    "            self.labels2.append(myAnnotion[i][9])\n",
    "        # print(self.filenames)\n",
    "        # print(self.labels1)\n",
    "        # print(self.labels2)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = os.path.join(self.img_folder, self.filenames[index])\n",
    "        label1 = self.labels1[index]\n",
    "        label2 = self.labels2[index]\n",
    "        img = spy.envi.open(img_name+'.hdr', img_name+'.img').read_bands([i for i in range(204)])\n",
    "        # print(img)\n",
    "        # img = plt.imread(img_name)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = torch.unsqueeze(self.transform(img).permute(1, 2, 0), dim=0) # \n",
    "        # print(img.shape)\n",
    "        # print('------')\n",
    "        # print(img_name)\n",
    "        # print('------')\n",
    "        # print(img.shape)\n",
    "\n",
    "\n",
    "        # return img, label\n",
    "        # print(self.img_folder)\n",
    "        return img, label1, label2#  + self.filenames[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_data\n",
    "    \n",
    "train_dataset = CIFAR10_IMG(r'E:\\my_project\\hyperspectralData\\medician\\leaf',train=\"Train\",transform=transforms.Compose([transforms.ToTensor(), transforms.Resize([16, 16])]))\n",
    "val_dataset = CIFAR10_IMG(r'E:\\my_project\\hyperspectralData\\medician\\leaf',train=\"Val\",transform=transforms.Compose([transforms.ToTensor(), transforms.Resize([16, 16])]))\n",
    "test_dataset = CIFAR10_IMG(r'E:\\my_project\\hyperspectralData\\medician\\leaf',train=\"Test\",transform=transforms.Compose([transforms.ToTensor(), transforms.Resize([16, 16])]))\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=6, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "# for step ,(b_x,b_y) in enumerate(train_loader):\n",
    "# for step, (img, label1, label2) in enumerate(train_loader):\n",
    "#     if step < 1:\n",
    "#         print(img, label1, label2)\n",
    "    #     imgs = utils.make_grid(b_x)\n",
    "    #     print(imgs.shape)\n",
    "    #     imgs = np.transpose(imgs,(1,2,0))\n",
    "    #     print(imgs.shape)\n",
    "    #     plt.imshow(imgs)\n",
    "    #     plt.show()\n",
    "\n",
    "    \n",
    "class Autoencoder1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder1, self).__init__()\n",
    "        # 编码器层\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(1, 8, kernel_size=[3, 3, 5], stride=1, padding=[1, 1, 0]),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool3d(kernel_size=[1, 1, 2], stride=[1, 1, 2]),\n",
    "            nn.Conv3d(8, 16, kernel_size=[3, 3, 21], stride=1, padding=[1, 1, 0]),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool3d(kernel_size=[1, 1, 2], stride=[1, 1, 2]),\n",
    "            nn.Conv3d(16, 1, kernel_size=[3, 3, 21], stride=1, padding=[1, 1, 0]),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool3d(kernel_size=[1, 1, 2], stride=[1, 1, 2])\n",
    "        )\n",
    "        \n",
    "        # 解码器层\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(1, 16, kernel_size=[1, 1, 21], stride=[1, 1, 2], padding=[0, 0, 0], output_padding=[0, 0, 1]),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose3d(16, 8, kernel_size=[1, 1, 21], stride=[1, 1, 2], padding=[0, 0, 0], output_padding=[0, 0, 1]),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose3d(8, 1, kernel_size=[1, 1, 5], stride=[1, 1, 2], padding=[0, 0, 0], output_padding=[0, 0, 1]),\n",
    "            nn.Sigmoid()\n",
    "            # nn.ReLU(True)\n",
    "            # nn.ConvTranspose3d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            # nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# 初始化模型\n",
    "# model1 = Autoencoder()\n",
    "model = Autoencoder1()\n",
    "modelname = r'E:\\my_project\\hyperspectralData\\medician\\myPth\\dimensionalityReduction\\autoEncoder/autoEncoder.pth'\n",
    "\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.BCELoss()\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002) # 0.001\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "# 加载高光谱数据\n",
    "# data = torch.randn(1, 1, 16, 16, 204)\n",
    "data = torch.randn(1, 16, 16, 204)\n",
    "# print(data.shape, model1(data).shape)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 0\n",
    "lossMin = 2\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    lossTatol = 0\n",
    "    t = tqdm.tqdm(enumerate(train_loader),desc = f'[train]') # ,loss:{loss.item()}\n",
    "    for step, (img, label1, label2) in t:\n",
    "        # if step < 1:\n",
    "        #     print(img.shape, label1.shape, label2.shape)\n",
    "    # 前向传播\n",
    "        # print('---', step, '---')\n",
    "        output = model(img.to(device))\n",
    "        loss = criterion(output, img.to(device))\n",
    "        # print(loss.item())\n",
    "        # break\n",
    "        lossTatol += loss.item()\n",
    "        # print(output[0,0,0,0,0], data[0,0,0,0,0])\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    lossAverage = lossTatol/(step+1)\n",
    "    # if lossAverage < lossMin:\n",
    "    #     lossMin = lossAverage\n",
    "    #     torch.save(model.state_dict(),modelname)\n",
    "    #     print('Epoch [{}/{}], Model Saved!! AverageLoss: {:.4f}, loss: {:.4f}, lossMin: {:.4f}'.format(epoch+1, num_epochs, lossAverage, loss.item(), lossMin))\n",
    "    # # 打印训练信息\n",
    "    # else:\n",
    "    #     print('Epoch [{}/{}], AverageLoss: {:.4f}, loss: {:.4f}, lossMin: {:.4f}'.format(epoch+1, num_epochs, lossAverage, loss.item(), lossMin))\n",
    "    print('Epoch [{}/{}], AverageLoss: {:.4f}, loss: {:.4f}'.format(epoch+1, num_epochs, lossAverage, loss.item()))\n",
    "\n",
    "    model.eval()\n",
    "    # 模型测试\n",
    "    lossTatol = 0\n",
    "    t = tqdm.tqdm(enumerate(val_loader),desc = f'[Val]') # ,loss:{loss.item()}\n",
    "    for step, (img, label1, label2) in t:\n",
    "        output = model(img.to(device))\n",
    "        loss = criterion(output, img.to(device))\n",
    "        # print(img[0,0,0,0,0], output[0,0,0,0,0])\n",
    "        lossTatol += loss.item()\n",
    "\n",
    "    lossAverage = lossTatol/(step+1)\n",
    "    if lossAverage < lossMin:\n",
    "        lossMin = lossAverage\n",
    "        torch.save(model.state_dict(),modelname)\n",
    "        print('Model Saved!! AverageLoss: {:.4f}, loss: {:.4f}, lossMin: {:.4f}'.format(lossAverage, loss.item(), lossMin))\n",
    "    # 打印训练信息\n",
    "    else:\n",
    "        print('AverageLoss: {:.4f}, loss: {:.4f}, lossMin: {:.4f}'.format(lossAverage, loss.item(), lossMin))\n",
    "    # print(lossAverage, loss.item())\n",
    "    print(' ')\n",
    "# 获取降维后的数据\n",
    "compressed_data = model.cpu().encoder(data)\n",
    "# print(compressed_data.shape)\n",
    "# compressed_data = compressed_data.view(-1, 16, 16, 10)\n",
    "# print('Compressed data shape:', compressed_data.shape)\n",
    "\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(modelname))\n",
    "    print('[INFO] Load Model complete')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model.eval()\n",
    "# 模型测试\n",
    "lossTatol = 0\n",
    "t = tqdm.tqdm(enumerate(test_loader),desc = f'[Test]') # ,loss:{loss.item()}\n",
    "for step, (img, label1, label2) in t:\n",
    "    compressed_data = model.cpu().encoder(img)\n",
    "    # view_cube(compressed_data[0,0].detach().numpy(), bands=[7,8,9])\n",
    "    # view_cube(img[0,0].detach().numpy(), bands=[13,36,48])\n",
    "    # view_cube(model.cpu().decoder((compressed_data))[0,0].detach().numpy(), bands=[13,36,48])\n",
    "    # view_cube(img[0,0].detach().numpy(), bands=[7,8,9])\n",
    "    view_cube(model.cpu().decoder((compressed_data))[0,0].detach().numpy(), bands=[7,8,9])\n",
    "    # view_cube(compressed_data[0,0].detach().numpy(), bands=[3,6,9])\n",
    "    # print(compressed_data.shape)\n",
    "    # print(compressed_data[0,0])\n",
    "    for i in range(10):\n",
    "        plt.subplot(5, 2, i+1)\n",
    "        plt.imshow(compressed_data[0,0,:, :, i].detach().numpy(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    # for i in range(204):\n",
    "    #     plt.subplot(17, 12, i+1)\n",
    "    #     plt.imshow(model.cpu().decoder((compressed_data))[0,0,:, :, i].detach().numpy(), cmap='gray')\n",
    "    #     plt.axis('off')\n",
    "    #     plt.show()\n",
    "    break\n",
    "    output = model(img)\n",
    "    loss = criterion(output, img)\n",
    "    \n",
    "    lossTatol += loss.item()\n",
    "\n",
    "# lossAverage = lossTatol/(step+1)\n",
    "\n",
    "# print('lossAverage:', lossAverage, 'loss:', loss.item())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyperSpectralDataHandle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
